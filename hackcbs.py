# -*- coding: utf-8 -*-
"""Hackcbs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bUwiouyhn8lMXxU2q5oqB3u0AViFZhQC
"""

import os
import pandas as pd
import tensorflow as tf
import tensorflow_hub as hub
#train_data = pd.read_csv('/content/train.txt', sep = ';')
#train_data.head()


def preprocess(file):
    path = os.getcwd()+'\\'+file+'.txt'
    data = pd.read_csv(path, sep = ';')
    hos = []
    for i in range(len(data.emotion)):
        if data['emotion'][i] in ['joy', 'love', 'surprise']:
            hos.append(1) # happy is 1
        else:
            hos.append(0) # sad is 0
    data['hos'] = hos
    return data

train_data = preprocess('train')
train = train_data.copy()

#train['emotion'].value_counts()

#train[train.emotion == 'surprise']['text'].head(10)

#train.groupby('hos').describe()

model = "https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1"
hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], 
                           dtype=tf.string, trainable=True)
#hub_layer(train['text'][:3])

model = tf.keras.Sequential()
model.add(hub_layer)
model.add(tf.keras.layers.Dense(16, activation='relu'))
model.add(tf.keras.layers.Dense(1))

#model.summary()

model.compile(optimizer='adam',
              loss=tf.losses.BinaryCrossentropy(from_logits=True),
              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])

val = preprocess('val')
#val.head()

history = model.fit(train.text,
                    train.hos,
                    epochs=40,
                    batch_size=512,
                    validation_data=(val.text, val.hos),
                    verbose = 0)

#test = preprocess('test')
#results = model.evaluate(test['text'], test['hos'])

#print(results)

#preds = model.predict(test.text)

predstr = model.predict(train.text)

#print(predstr.min(), predstr.max())

#print(preds.min(), preds.max())

def postprocessor(preds):
  range = predstr.max()-predstr.min()
  norm_preds = []
  probab = []
  for i in preds:
    norm_preds.append((i - predstr.min()) / range)
    probab.append((i - predstr.min()) * 100 / range)
  return np.mean(probab)

final_result = postprocessor(preds)
print(final_result)
model.save(os.getcwd()+'\\model'+".h5")

